<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>/Private Local AI</title>

  <link rel="stylesheet" href="./../styles.css">

  <link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/@mdi/font@4.x/css/materialdesignicons.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/vuetify@2.x/dist/vuetify.min.css" rel="stylesheet">
</head>
<body>
  <div id="app">
    <v-app>
      <button class="back-button" onclick="goBack()">&larr; cd ..</button>

      <main class="container">
        <section>

          <h1 class="display-4">/Private Local AI</h1>

          <div class="article-content">
            üóìÔ∏è 02 Jan 2025 - üëª Yusuf Amr
            
            <img src="./assets/private_ai/private ai.jpg" alt="Description of the image" >
            <span class="highlight">Why Local Private AI?</span>
            I‚Äôve often been concerned about the accidental leakage of sensitive information through AI tools. Users, in their day-to-day work, may unknowingly share critical data with public AI platforms, potentially exposing confidential information. Additionally, some AI platforms might unintentionally reveal sensitive data through carefully crafted prompts, where a user manipulates the model to retrieve information it might have stored or cached.

            In this article, I‚Äôll share how I‚Äôve approached implementing a local, private AI solution within a secure environment, where all data is stored privately on the machine hosting the AI.

            <span class="highlight">To implement this, I chose OpenWebUI platform. It offered several advantages that made it ideal for my needs:</span>
    - <b>Web Interface:</b> OpenWebUI functions as a web interface.
    - <b>Network Accessibility:</b> It is accessible by devices on the same network.
    - <b>Robust Retrieval-Augmented Generation (RAG):</b> This feature enhances the AI‚Äôs ability to retrieve and use context-specific information.
    - <b>Ease of Integration:</b> OpenWebUI supports straightforward API integrations, making it easier to connect with various data sources and tools.
    - <b>Data Localization:</b> All data is processed and stored locally, ensuring that nothing leaves the organization's secure environment.

<span class="highlight">Implementation Steps:</span>
To set up OpenWebUI, I used an Ubuntu virtual machine running on VirtualBox. Below is an overview of the steps I followed:

    -><b>Setting Up the Virtual Environment:</b>
        Installed VirtualBox and created a new Ubuntu virtual machine (VM).
        Configured the network settings to ensure access across devices within the LAN.

    -><b>Installing OpenWebUI:</b>
        OpenWebUI requires Python 3.11, but Ubuntu's default version was Python 3.12. To address this, I Installed Python 3.11 and set up a virtual environment called myenv, ensuring that Python packages are isolated for the project:
        <pre><code>
        sudo apt install python3.11 python3.11-venv
        sudo ln -sf /usr/bin/python3.11 /usr/bin/python3
        python3 -m venv myenv
        source myenv/bin/activate
        pip install open-webui
        deactivate
    </code></pre>
        Installed OpenWebUI inside the virtual environment using python 3.11 and for the model we will use python 3.12 outside the virtual environment.

   -><b>Integrating Meta‚Äôs Llama 3 2B Model:</b>

    To integrate Meta‚Äôs Llama 3 2B model, Installed the model outside the virtual environment and switched back to Python 3.12:
        <pre><code>
        sudo ln -sf /usr/bin/python3.12 /usr/bin/python3
        curl -fsSL https://ollama.com/install.sh | sh
        ollama run llama3:8b
    </code></pre>
        The model download was approximately 5GB, and once it was ready, I tested it through the OpenWebUI interface.

-><b>Running OpenWebUI:</b>
    To start OpenWebUI with Python 3.11, I used the following commands:
    <pre><code>
        sudo ln -sf /usr/bin/python3.11 /usr/bin/python3
        source myenv/bin/activate
        open-webui serve
    </code></pre>
        Once the server was running, I could access the AI interface through a browser at <b>http://localhost:8080</b>, where I could select the model and start interacting with the AI.
        <img src="./assets/private_ai/choose the model.png" alt="Description of the image" >
        <img src="./assets/private_ai/interface.png" alt="Description of the image" >
        <img src="./assets/private_ai/chat.png" alt="Description of the image" >
        <span class="highlight">API Integration:</span>
        One of the standout features of OpenWebUI is its connection tab, which allows easy integration of external APIs, such as Google Search or internal systems, for enhanced functionality.
        
        <img src="./assets/private_ai/connection.png" alt="Description of the image" >
<span class="highlight">Challenges and Lessons Learned</span>
    <b>- Resource Management:</b> Running models required significant computational resources, necessitating careful allocation of resources in the VM.
    <b>- User Adoption:</b> Transitioning users from public AI platforms to a private instance required careful communication of the security benefits and addressing concerns about usability.

<span class="highlight">Conclusion</span>
Implementing a local private AI solution, like OpenWebUI with ai model, proved to be an effective approach for enhancing security and ensuring data privacy. Not only did it strengthen our internal security posture, but it also demonstrated the feasibility of using AI in a controlled and secure environment. I highly recommend exploring this approach to protect sensitive information while leveraging the power of AI.

<span class="highlight">Resources:</span>
- <b>OpenWebUI:</b> <a href="https://github.com/open-webui/open-webui" target="_blank">https://github.com/open-webui/open-webui</a>
- <b>Ollama for linux:</b> <a href="https://ollama.com/download/linux " target="_blank">https://ollama.com/download/linux </a>
- <b>llama3:</b> <a href="https://ollama.com/library/llama3" target="_blank">https://ollama.com/library/llama3</a>
- <b>Ubuntu:</b> <a href="https://ubuntu.com/download/desktop" target="_blank">https://ubuntu.com/download/desktop</a>
- <b>VirtualBox:</b> <a href="https://www.virtualbox.org/wiki/Downloads" target="_blank">https://www.virtualbox.org/wiki/Downloads</a>



          </div>
        </section>
      </main>
    </v-app>
  </div>

  <!-- Scripts -->
  <script>

    function goBack() {
      window.history.back();
  }
  </script>
  <script src="https://cdn.jsdelivr.net/npm/vue@2.x/dist/vue.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/vuetify@2.x/dist/vuetify.js"></script>
</body>
</html>
